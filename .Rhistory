dt.out <- dt.out[order(dt.out$group, dt.out$time), ]
lag.df <- function(dt, x, by.group, time.var){
## create a temporary indicator variable to count the number of rows for each
## group
dt$temp.indicator.var_ <- 1
## count the number of rows (observations) per group ("by.group")
group.counts <- aggregate(dt$temp.indicator.var_, by = list(dt[, by.group]), FUN = sum)
## Find which groups have only one observation; if there are any such groups
## assign them to a list of "singletons". Later these will be given a NA
## value for their lagged value
o <- which(group.counts[[2]] < 2)
if(length(o) > 0) singletons <- group.counts[o, 1]
rm("o")
## Find the rows in the original dataset that correspond to these
## singleton groups; if there are any treat them differently when lagging;
## lag the values in "x" in the rows belonging to non-singleton groups.
o <- which(dt[, by.group] %in% singletons)
if(length(o) > 0){
dt1 <- dt[o, ]
dt2 <- dt[-o, ]
dt1[, paste(x, 'lag1', sep = '')] <- NA
## this is the workhorse lagging function
x.lag <- unlist(tapply(X = dt2[, x], INDEX = dt2[, by.group], FUN = lg))
dt2[, paste(x, 'lag1', sep = '')] <- x.lag
dt.out <- rbind(dt1, dt2)
}else{
x.lag <- unlist(tapply(X = dt2[, x], INDEX = dt2[, by.group], FUN = lg))
dt.out <- dt
dt.out[, paste(x, 'lag1', sep = '')] <- x.lag
}
## sort the dataframe that is to be returned to the user by its group and
## appropriate (user-defined and user-sorted) time variable
dt.out <- dt.out[order(dt.out[, by.group], dt.out[, time.var]), ]
return(dt.out)
}
dt = data.frame(matrix(rnorm(40), nrow = 20))
dt$group <- rep(c(1:5),4)
dt$time <- rep(101:104, 5)
dt <- dt[order(dt$group, dt$time), ]
dt[21, ] <- dt[20, ]
dt[22, ] <- dt[19, ]
dt[21, 'group'] <- 6
dt[22, 'group'] <- 1.5
dt = data.frame(matrix(rnorm(40), nrow = 20))
dt$group <- rep(c(1:5),4)
dt$time <- rep(101:104, 5)
dt[21, ] <- dt[20, ]
dt[22, ] <- dt[19, ]
dt[21, 'group'] <- 6
dt[22, 'group'] <- 1.5
dt <- dt[order(dt$group, dt$time), ]
lag.df(dt, "x2", "group", "time")
lag.df(dt, "X2", "group", "time")
rm(list = c("dt", "dt1", "dt2"))
rm("dt.out")
rm("group.counts")
rm("by.group")
rm("time")
rm("x")
rm("x.lag1")
rm("x.lag")
rm("x1")
rm("year")
rm("qtr")
rm("o")
comp.fundq <- comp.fundq[order(comp.fundq$gvkey, comp.fundq$datacqtr, decreasing = FALSE), ]
View(comp.fundq)
comp.fundq <- comp.fundq[order(comp.fundq$gvkey, comp.fundq$datacqtr), ]
X <- lag.df(dt = comp.fundq, x = "seqq", by.group = "gvkey", time.var = "qtr")
View(comp.fundq)
View(X)
lag.df <- function(dt, x, by.group, time.var){
## create a temporary indicator variable to count the number of rows for each
## group
dt$temp.indicator.var_ <- 1
## count the number of rows (observations) per group ("by.group")
group.counts <- aggregate(dt$temp.indicator.var_, by = list(dt[, by.group]), FUN = sum)
## Find which groups have only one observation; if there are any such groups
## assign them to a list of "singletons". Later these will be given a NA
## value for their lagged value
o <- which(group.counts[[2]] < 2)
if(length(o) > 0) singletons <- group.counts[o, 1]
rm("o")
## Find the rows in the original dataset that correspond to these
## singleton groups; if there are any treat them differently when lagging;
## lag the values in "x" in the rows belonging to non-singleton groups.
o <- which(dt[, by.group] %in% singletons)
if(length(o) > 0){
dt1 <- dt[o, ]
dt2 <- dt[-o, ]
dt1[, paste(x, 'lag1', sep = '')] <- NA
## this is the workhorse lagging function
x.lag <- unlist(tapply(X = dt2[, x], INDEX = dt2[, by.group], FUN = lg))
dt2[, paste(x, 'lag1', sep = '.')] <- x.lag
dt.out <- rbind(dt1, dt2)
}else{
x.lag <- unlist(tapply(X = dt2[, x], INDEX = dt2[, by.group], FUN = lg))
dt.out <- dt
dt.out[, paste(x, 'lag1', sep = '.')] <- x.lag
}
## sort the dataframe that is to be returned to the user by its group and
## appropriate (user-defined and user-sorted) time variable
dt.out <- dt.out[order(dt.out[, by.group], dt.out[, time.var]), ]
return(dt.out)
}
X <- lag.df(dt = comp.fundq, x = "seqq", by.group = "gvkey", time.var = "qtr")
lag.df <- function(dt, x, by.group, time.var){
## create a temporary indicator variable to count the number of rows for each
## group
dt$temp.indicator.var_ <- 1
## count the number of rows (observations) per group ("by.group")
group.counts <- aggregate(dt$temp.indicator.var_, by = list(dt[, by.group]), FUN = sum)
## Find which groups have only one observation; if there are any such groups
## assign them to a list of "singletons". Later these will be given a NA
## value for their lagged value
o <- which(group.counts[[2]] < 2)
if(length(o) > 0) singletons <- group.counts[o, 1]
rm("o")
## Find the rows in the original dataset that correspond to these
## singleton groups; if there are any treat them differently when lagging;
## lag the values in "x" in the rows belonging to non-singleton groups.
o <- which(dt[, by.group] %in% singletons)
if(length(o) > 0){
dt1 <- dt[o, ]
dt2 <- dt[-o, ]
dt1[, paste(x, 'lag1', sep = '.')] <- NA
## this is the workhorse lagging function
x.lag <- unlist(tapply(X = dt2[, x], INDEX = dt2[, by.group], FUN = lg))
dt2[, paste(x, 'lag1', sep = '.')] <- x.lag
dt.out <- rbind(dt1, dt2)
}else{
x.lag <- unlist(tapply(X = dt2[, x], INDEX = dt2[, by.group], FUN = lg))
dt.out <- dt
dt.out[, paste(x, 'lag1', sep = '.')] <- x.lag
}
## sort the dataframe that is to be returned to the user by its group and
## appropriate (user-defined and user-sorted) time variable
dt.out <- dt.out[order(dt.out[, by.group], dt.out[, time.var]), ]
return(dt.out)
}
X <- lag.df(dt = comp.fundq, x = "seqq", by.group = "gvkey", time.var = "qtr")
lag.df <- function(dt, x, by.group, time.var){
## create a temporary indicator variable to count the number of rows for each
## group
dt$temp.indicator.var_ <- 1
## count the number of rows (observations) per group ("by.group")
group.counts <- aggregate(dt$temp.indicator.var_, by = list(dt[, by.group]), FUN = sum)
## Find which groups have only one observation; if there are any such groups
## assign them to a list of "singletons". Later these will be given a NA
## value for their lagged value
o <- which(group.counts[[2]] < 2)
if(length(o) > 0) singletons <- group.counts[o, 1]
rm("o")
## Find the rows in the original dataset that correspond to these
## singleton groups; if there are any treat them differently when lagging;
## lag the values in "x" in the rows belonging to non-singleton groups.
o <- which(dt[, by.group] %in% singletons)
if(length(o) > 0){
dt1 <- dt[o, ]
dt2 <- dt[-o, ]
dt1[, paste(x, 'lag1', sep = '.')] <- NA
## this is the workhorse lagging function
x.lag <- unlist(tapply(X = dt2[, x], INDEX = dt2[, by.group], FUN = lg))
dt2[, paste(x, 'lag1', sep = '.')] <- x.lag
dt.out <- rbind(dt1, dt2)
}else{
x.lag <- unlist(tapply(X = dt2[, x], INDEX = dt2[, by.group], FUN = lg))
dt.out <- dt
dt.out[, paste(x, 'lag1', sep = '.')] <- x.lag
}
## sort the dataframe that is to be returned to the user by its group and
## appropriate (user-defined and user-sorted) time variable
dt.out <- dt.out[order(dt.out[, by.group], dt.out[, time.var]), ]
dt.out$temp.indicator.var_ <- NULL
return(dt.out)
}
X <- lag.df(dt = comp.fundq, x = "seqq", by.group = "gvkey", time.var = "qtr")
lead.df <- function(dt, x, by.group, time.var){
x.lead <- unlist(tapply(X = dt[, x], INDEX = dt[, by.group], FUN = ld))
dt.out <- dt
dt.out[, paste(x, 'lead1', sep = '.')] <- x.lead
## sort the dataframe that is to be returned to the user by its group and
## appropriate (user-defined and user-sorted) time variable
dt.out <- dt.out[order(dt.out[, by.group], dt.out[, time.var]), ]
return(dt.out)
}
dt = data.frame(matrix(rnorm(40), nrow = 20))
dt$group <- rep(c(1:5),4)
dt$time <- rep(101:104, 5)
dt[21, ] <- dt[20, ]
dt[22, ] <- dt[19, ]
dt[21, 'group'] <- 6
dt[22, 'group'] <- 1.5
dt <- dt[order(dt$group, dt$time), ]
lead.df(dt, "X1", "group", "time")
dt = data.frame(matrix(rnorm(40), nrow = 20))
dt$group <- rep(c(1:5),4)
dt$time <- rep(101:104, 5)
dt[21, ] <- dt[20, ]
dt[22, ] <- dt[19, ]
dt[21, 'group'] <- 6
dt[22, 'group'] <- 1.5
dt <- dt[order(dt$group, dt$time), ]
View(dt)
ld <- function(x){
n <- length(x)
y <- c(x[2:n], NA)
}
lead.df <- function(dt, x, by.group, time.var){
x.lead <- unlist(tapply(X = dt[, x], INDEX = dt[, by.group], FUN = ld))
dt.out <- dt
dt.out[, paste(x, 'lead1', sep = '.')] <- x.lead
## sort the dataframe that is to be returned to the user by its group and
## appropriate (user-defined and user-sorted) time variable
dt.out <- dt.out[order(dt.out[, by.group], dt.out[, time.var]), ]
return(dt.out)
}
lead.df(dt, "X1", "group", "time")
lead.df(dt, "X1", "group", "time")
by.group <- "group"
time.var <- "time"
x <- "X1"
x.lead <- unlist(tapply(X = dt[, x], INDEX = dt[, by.group], FUN = ld))
ld(dt[,x])
ld <- function(x){
n <- length(x)
y <- c(x[2:n], NA)
return(y)
}
ld(dt[,x])
lead.df <- function(dt, x, by.group, time.var){
x.lead <- unlist(tapply(X = dt[, x], INDEX = dt[, by.group], FUN = ld))
dt.out <- dt
dt.out[, paste(x, 'lead1', sep = '.')] <- x.lead
## sort the dataframe that is to be returned to the user by its group and
## appropriate (user-defined and user-sorted) time variable
dt.out <- dt.out[order(dt.out[, by.group], dt.out[, time.var]), ]
return(dt.out)
}
lead.df(dt, "X1", "group", "time")
x.lead <- unlist(tapply(X = dt[, x], INDEX = dt[, by.group], FUN = ld))
unlist(tapply(X = dt[, x], INDEX = dt[, by.group], FUN = ld))
tapply(X = dt[, x], INDEX = dt[, by.group], FUN = ld)
ld(1:5)
ld(dt[which(dt["by.group"] == 1.5), "X1"])
which(dt["by.group"] == 1.5)
which(dt[, "by.group"] == 1.5)
by.group
ld(dt[which(dt[by.group] == 1.5), "X1"])
ld <- function(x){
n <- length(x)
if(n <2){
y <- NA
}
y <- c(x[2:n], NA)
return(y)
}
ld(1)
ld <- function(x){
n <- length(x)
if(n <2){
y <- NA
}else{
y <- c(x[2:n], NA)
}
return(y)
}
ld(1)
ld(c(1,2))
lead.df <- function(dt, x, by.group, time.var){
x.lead <- unlist(tapply(X = dt[, x], INDEX = dt[, by.group], FUN = ld))
dt.out <- dt
dt.out[, paste(x, 'lead1', sep = '.')] <- x.lead
## sort the dataframe that is to be returned to the user by its group and
## appropriate (user-defined and user-sorted) time variable
dt.out <- dt.out[order(dt.out[, by.group], dt.out[, time.var]), ]
return(dt.out)
}
lead.df(dt, "X1", "group", "time")
lg <- function(x){
n <- length(x)
if(n < 2){
y <- NA
}else{
y <- c(NA, x[1:(n-1)])
}
return(y)
}
lag.df2 <- function(dt, x, by.group, time.var){
x.lag <- unlist(tapply(X = dt[, x], INDEX = dt[, by.group], FUN = lg))
dt.out <- dt
dt.out[, paste(x, 'lag1', sep = '.')] <- x.lag
## sort the dataframe that is to be returned to the user by its group and
## appropriate (user-defined and user-sorted) time variable
dt.out <- dt.out[order(dt.out[, by.group], dt.out[, time.var]), ]
return(dt.out)
}
dt = data.frame(matrix(rnorm(40), nrow = 20))
dt$group <- rep(c(1:5),4)
dt$time <- rep(101:104, 5)
dt[21, ] <- dt[20, ]
dt[22, ] <- dt[19, ]
dt[21, 'group'] <- 6
dt[22, 'group'] <- 1.5
dt <- dt[order(dt$group, dt$time), ]
lag.df2(dt, "X2", "group", "time")
x <- lag.variable(comp.fundq, "qtr", "gvkey")
x <- lag.variable(comp.fundq, "qtr", "gvkey", "qtr")
X <- lag.df(dt = comp.fundq, x = "seqq", by.group = "gvkey", time.var = "qtr")
X <- lag.df(comp.fundq, "qtr", "gvkey", "qtr")
X$gap <- X$qtr - X$qtr.lag1
X <- lead.df(comp.fundq, "seqq", "gvkey", "qtr")
## Reginald Edwards
## 11 June 2018
## 16 June 2018
## Import quarterly Compustat fundamentals data
## Clean and filter the data
## Generate features for modeling
## Compute quarterly financial ratios.
###############################################################################
rm(list=ls())
gc()
library(RPostgres)
source("../0_code/useful-fn.R")
#wrds <- dbConnect(Postgres(),  host='wrds-pgdata.wharton.upenn.edu', port=9737, user='reggie09', password='gbHjz5FV', sslmode='require', dbname='wrds')
## Raw Compustat data are in a PostgresQL database "import.comp_fundq"
localdb <- dbConnect(Postgres(),
host='localhost',
port=5432,
user='postgres',
password = 'havoc')
###############################################################################
## Retrieve compustat fundamentals from SQL database
###############################################################################
res <- RPostgres::dbSendQuery(conn = localdb, statement = "SELECT * FROM fundq_short;")
#comp.fundq <- RPostgres::dbFetch(res, n = 100)
comp.fundq <- RPostgres::dbFetch(res)
RPostgres::dbClearResult(res)
## number of observations of "baseline" data
n <- nrow(comp.fundq)
###############################################################################
## Convert character variables to numeric variables, date variables etc. as
## appropriate.
###############################################################################
vars <- c("apq",
"ajexq",
"atq",
"capxy",
"cheq",
"cshoq",
"ceqq",
"cogsq",
"actq",
"lctq",
"dlcq",
"txdbq",
"txditcq",
"dpcy",
"dpq",
"dvpq",
"dvpy",
"oepsxy",
"epspxq",
"epsfxq",
"epsfiq",
"opepsq",
"xidoq",
"ibq",
"ibadjq",
"ibcomq",
"ibcy",
"txtq",
"txpq",
"xintq",
"invtq",
"icaptq",
"ltq",
"dlttq",
"niq",
"miiq",
"mibq",
"nopiq",
"oancfy",
"xoprq",
"oiadpq",
"oibdpq",
"pstkrq",
"pstkq",
"piq",
"prccq",
"ppentq",
"rectq",
"xrdq",
"revtq",
"saleq",
"xsgaq",
"spiq",
"seqq")
X <- comp.fundq
for(v in vars) X[,v] <- as.numeric(X[,v])
comp.fundq <- X
rm("X")
###############################################################################
## Create a global "quarter" time variable as quarters since the first
## quarter of 1960
###############################################################################
get.quarter <- function(x){
## x is a datacqtr from Compustat
year <- as.numeric(substr(x, 1, 4))
qtr <- as.numeric(substr(x, 6,6))
return((year - 1960)*4 + qtr)
}
comp.fundq$qtr <- get.quarter(comp.fundq$datacqtr)
###############################################################################
## Apply some data filters
###############################################################################
## Create a table for keeping track of data filters and observations at each
## step.
comp.fundq.filters <- data.frame(matrix(NA, nrow = 0, ncol = 2))
names(comp.fundq.filters) <- c("data.filter", "obs.remaining")
comp.fundq.filters[1, ] <- c("baseline", nrow(comp.fundq))
## Data filters, from most to least essential
## 1. Positive total assets that are not missing (atq > 0)
comp.fundq <- comp.fundq[-which(is.na(comp.fundq$atq)), ]
comp.fundq <- comp.fundq[comp.fundq$atq > 0 , ]
comp.fundq.filters[nrow(comp.fundq.filters) + 1, ] <- c("atq_gt_0", nrow(comp.fundq))
## 2. Positive revenue/sales that are not missing (saleq > 0)
comp.fundq <- comp.fundq[-which(is.na(comp.fundq$saleq)), ]
comp.fundq <- comp.fundq[comp.fundq$saleq > 0, ]
comp.fundq.filters[nrow(comp.fundq.filters) + 1, ] <- c("saleq_gt_0", nrow(comp.fundq))
## 3. Non-missing stock price at end of quarter greater than $2 per share (prccq > 2)
comp.fundq <- comp.fundq[-which(is.na(comp.fundq$prccq)), ]
comp.fundq <- comp.fundq[comp.fundq$prccq > 2, ]
comp.fundq.filters[nrow(comp.fundq.filters) + 1, ] <- c("prccq_gt_2", nrow(comp.fundq))
## 4. EPS is not missing (epspxq not NA)
comp.fundq <- comp.fundq[-which(is.na(comp.fundq$epspxq)), ]
comp.fundq.filters[nrow(comp.fundq.filters) + 1, ] <- c("epspxq_not_na", nrow(comp.fundq))
## 5. Date is not missing
comp.fundq <- comp.fundq[!(comp.fundq$datacqtr == ""), ]
comp.fundq <- comp.fundq[!(comp.fundq$datadate == ""), ]
comp.fundq.filters[nrow(comp.fundq.filters) + 1, ] <- c("date_not_na", nrow(comp.fundq))
## . Remove firms with fewer than 20 quarters (5 years) of continuous EPS data
## TODO: Deal with gaps
###############################################################################
## Lag and lead Variables
###############################################################################
## Sort by gvkey and quarter
comp.fundq <- comp.fundq[order(comp.fundq$gvkey, comp.fundq$datacqtr), ]
## Create a lag of quarter time variable to check for gaps in the time series
## for each firm.
comp.fundq <- lag.df(comp.fundq, "qtr", "gvkey", "qtr")
comp.fundq$gap <- comp.fundq$qtr - comp.fundq$qtr.lag1
hist(comp.fundq$gap)
quantile(comp.fundq$gap)
quantile(comp.fundq$gap, na.rm = TRUE)
table(comp.fundq$gap)
table(comp.fundq$gap)/nrow(comp.fundq)
100*table(comp.fundq$gap)/nrow(comp.fundq)
round(100*table(comp.fundq$gap)/nrow(comp.fundq),2)
comp.fundq <- lead.df(comp.fundq, "epspxq", "gvkey", "qtr")
comp.fundq <- comp.fundq[order(comp.fundq$gvkey, comp.fundq$datacqtr, decreasing = FALSE), ]
save(comp.fundq, file = 'data/comp_fundq.RData')
## Reginald Edwards
## 16 June 2018
##
##
rm(list=ls())
gc()
load("data/comp_fundq.RData")
X <- comp.fundq
###############################################################################
## Linear Models
###############################################################################
## Linear Regression
linreg1 <- lm(epspxq.lead1 ~ epspxq, data = comp.fundq)
summary(linreg1)
rm(list=ls())
gc()
load("data/comp_fundq.RData")
X <- comp.fundq[comp.fundq$tic == 'MSI',]
View(X)
getwd()
dir()
setwd("C:/Users/Reginald/Dropbox/Research/earnings")
load("data/compa.RData")
X <- compa[compa$tic == 'MSI',]
X <- compa[compa$oftic == 'MSI',]
rm(list=ls())
gc()
load('../0_datasets/comp_funda.RData')
X <- comp.funda[comp.funda$tic == 'MSI',]
X$sich
sic <- 3663
sic2 <- 36
x <- int(X$sich/100)
x <- trunc(X$sich/100)
x
comp.funda$sic2 <- trunc(comp.funda$sich/100)
X <- comp.funda[comp.funda$sic2 == 36, ]
table(comp.funda$sic2)
X <- comp.funda[which(comp.funda$sic2 == 36), ]
X <- comp.funda[which(comp.funda$fyear == 2016), ]
X <- comp.funda[which(comp.funda$sic2 == 36), ]
X <- X[which(X$fyear == 2016), ]
View(X)
X$tic
X <- X[, c("tic", "gvkey", "conm")]
X <- comp.funda[which(comp.funda$sic2 == 36), ]
X <- X[which(X$fyear == 2016), ]
X <- X[, c("tic","cik", "gvkey", "conm")]
X <- X[order(X$tic), ]
length(!which(is.na(comp.funda$cik)))
